{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals \n",
    "\n",
    "1. 딥러닝 모델 학습에 필요한 이미지 데이터셋을 불러오고, 전처리하는 방법 실습\n",
    "2. CNN 모델을 구현하고, 학습하는 방법 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EisAPHJGG7qj"
   },
   "source": [
    "## 1. 데이터셋 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zV6Rooo0HBYk"
   },
   "source": [
    "### 데이터셋 불러오기\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/datasets\n",
    "\n",
    "- FashionMNIST 데이터셋을 Tensorflow에서 제공하는 API를 통해 로드\n",
    "\n",
    "    - `x_train`: 학습에 사용되는 이미지 데이터\n",
    "    - `y_train`: 학습에 사용되는 레이블\n",
    "\n",
    "    - `x_test`: 성능 평가 (테스트)에 사용되는 이미지 데이터\n",
    "    - `y_test`: 성능 평가 (테스트)에 사용되는 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "g3lfL84LG2X_"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9l0a6UlNHG9V"
   },
   "source": [
    "### 데이터셋 정보 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터셋을 구성하는 Tensor의 shape 확인\n",
    "    - Tensorflow의 `Tensor` 객체는 이미지 데이터를 나타내는 3차원 Tensor를 사용 \n",
    "    - Tensor의 shape은 `(이미지 개수, 이미지 높이, 이미지 너비, 채널 수)`로 구성\n",
    "    - 컬러 이미지의 경우 채널 수가 3 (RGB) 이며, 흑백 이미지의 경우 채널 수가 1 (따라서 shape에서 생략됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZ0x4yUwHOax",
    "outputId": "d513be1e-b73e-4dca-ee76-c4e263364678"
   },
   "outputs": [],
   "source": [
    "print(\"아래 셀에서 보이는 것처럼 FashionMNIST 데이터셋은 흑백 이미지로 구성되어 있으므로, 채널 수가 1, 높이와 너비는 각각 28\")\n",
    "print('학습 데이터 shape:', x_train.shape)\n",
    "print('테스트 데이터 shape:', x_test.shape)\n",
    "\n",
    "print('학습 라벨 shape:', y_train.shape)\n",
    "print('테스트 라벨 shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 총 10개의 클래스가 존재하며, 각 클래스는 다음과 같은 정수로 레이블링\n",
    "    - 0: T-shirt/top\n",
    "    - 1: Trouser\n",
    "    - 2: Pullover\n",
    "    - 3: Dress\n",
    "    - 4: Coat\n",
    "    - 5: Sandal\n",
    "    - 6: Shirt\n",
    "    - 7: Sneaker\n",
    "    - 8: Bag\n",
    "    - 9: Ankle boot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "\n",
    "print('클래스 별 학습 데이터 수')\n",
    "for i in range(10):\n",
    "    print(f'{i}번 클래스: {class_names[i]}', y_train[y_train == i].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 시간 단축을 위해서 60,000개의 학습 데이터 중 10,000개를 랜덤 추출하여 사용\n",
    "\n",
    "- numpy의 `np.random.choice` API를 사용하여 랜덤 추출된 인덱스를 저장하는 `indices` 변수를 생성하고, `x_train`과 `y_train`에서 랜덤으로 추출된 10,000개의 데이터를 저장\n",
    "    -  https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random index sampling (0 ~ 59999 의 정수 중 랜덤으로 10000개를 샘플링)\n",
    "random_idx = np.random.choice(60000, 10000, replace=False)\n",
    "print(random_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플링된 인덱스로 데이터셋 서브샘플링 (10000개), numpy 어레이 인덱싱 활용\n",
    "x_train = x_train[random_idx]\n",
    "y_train = y_train[random_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"아래 셀에서 보이는 것처럼 FashionMNIST 데이터셋은 흑백 이미지로 구성되어 있으므로, 채널 수가 1, 높이와 너비는 각각 28\")\n",
    "print('학습 데이터 shape:', x_train.shape)\n",
    "print('테스트 데이터 shape:', x_test.shape)\n",
    "\n",
    "print('학습 라벨 shape:', y_train.shape)\n",
    "print('테스트 라벨 shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "\n",
    "print('클래스 별 학습 데이터 수')\n",
    "for i in range(10):\n",
    "    print(f'{i}번 클래스: {class_names[i]}', y_train[y_train == i].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDC9CNLdIdci"
   },
   "source": [
    "### 데이터 이미지 확인\n",
    "\n",
    "- `matplotlib` 패키지를 활용한 시각화를 통해 데이터 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "MU85wln8HYFk",
    "outputId": "dde9d6b1-ed45-4979-c208-d18a7dcc6e34"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "\n",
    "i = 140\n",
    "# 학습 데이터셋의 i 번째 이미지를 시각화\n",
    "image = x_train[i]\n",
    "label = y_train[i]\n",
    "\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azPoZD2uIsvf"
   },
   "source": [
    "### 데이터 로더 준비\n",
    "\n",
    "- 이미지 데이터의 픽셀 값은 0~255 사이의 값을 가짐\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjVqznT-IzPv",
    "outputId": "ddc8d815-ebb4-4710-d34f-d78077781aa6"
   },
   "outputs": [],
   "source": [
    "print('최대 픽셀 값', x_train.max())\n",
    "print('최소 픽셀 값', x_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딥러닝 모델 학습 시, 각 픽셀 값 범위를 0~1 사이로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bPjqqzUsJO5P"
   },
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDxst3KMJbKT",
    "outputId": "3a068021-170e-41d1-e2fe-ccc10ae49681"
   },
   "outputs": [],
   "source": [
    "print('최대 픽셀 값', x_train.max())\n",
    "print('최소 픽셀 값', x_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stochastic (Mini-batch) gradient descent 알고리즘을 통한 모델 학습을 위해 데이터를 적절한 크기로 잘라서 학습에 활용\n",
    "    - Tensorflow의 `Dataset` 패키지를 활용, 전체 데이터를 배치 단위로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "c7Cidy3J9uPc"
   },
   "outputs": [],
   "source": [
    "# 학습/테스트 데이터셋 배치 로더 정의\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "tf_train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "tf_test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "train_batch_loader = tf_train_dataset.shuffle(buffer_size=100000).batch(batch_size)\n",
    "test_batch_loader = tf_test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 배치 단위로 분할된 `train_batch_loader`, `test_batch_loader`는 아래와 같이 반복문을 통해 iterate 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋의 모든 데이터 (10000개)가 한번씩 뽑힐 때 까지 batch size 만큼 데이터 반환\n",
    "for x, y in train_batch_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4IiXG6oHGLE"
   },
   "source": [
    "# 2-1. CNN 모델 정의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkiSwjOPLBTh"
   },
   "source": [
    "### Dense (Fully-Connected) Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjqh3ffLLJUm"
   },
   "source": [
    "- 입력 vector $x$ 를 받아 학습 파라미터 $W$와의 $W^Tx = y$ 을 수행하는 레이어 \n",
    "\n",
    "- 입력 벡터가 $x\\in \\mathbb{R}^{\\text{in}}$, 출력 벡터가 $y\\in \\mathbb{R}^{\\text{out}}$의 차원을 갖는 경우 $W$의 차원은 $\\mathbb{R}^{\\text{in}\\times \\text{out}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dense layer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dimension = 128\n",
    "dense_layer = tf.keras.layers.Dense(units=output_dimension, activation='relu') # y= = Relu(Dense(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 랜덤 입력 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kA43rtmZKe6-",
    "outputId": "932e6d46-b45a-4b33-e1ec-adf864a71785"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "input_dimension = 32\n",
    "input = tf.random.normal(shape=[batch_size, input_dimension])\n",
    "\n",
    "print('random input shape: ', input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_0T1l8IMT8K"
   },
   "source": [
    "- Dense layer 연산 (forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ydDXQuLK5Ax",
    "outputId": "91ea3cf9-4a33-4377-b0c4-41f74c62e1cc"
   },
   "outputs": [],
   "source": [
    "output = dense_layer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('output shape: ', output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dense layer의 학습 파라미터 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwcdvOD2LiF3"
   },
   "source": [
    "### Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5RiXEWQNl3s"
   },
   "source": [
    "- (height, width, channel)의 shape을 갖는 이미지 데이터를 입력으로 받아, 컨볼루션 필터를 이용해 이미지 데이터에 대한 합성곱 연산을 수행하는 레이어\n",
    "- 2차원 이미지 데이터를 dense layer가 처리 가능한 1차원 데이터로 변환하기 위해서 Flatten layer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AeJT20RWOBK0",
    "outputId": "84f1848a-38b0-41a6-8042-d4187cdc0d79"
   },
   "outputs": [],
   "source": [
    "# filters: 출력 채널 수\n",
    "# kernel_size: 컨볼루션 필터 크기\n",
    "# padding: 입력 이미지에 부여되는 패딩 규칙 ('same' 일 경우 입력과 출력의 너비와 높이가 변하지 않음)\n",
    "conv_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "input_height = 28\n",
    "input_width = 28\n",
    "input_channel = 1\n",
    "input = tf.random.normal(shape=[100, 28, 28, 1])\n",
    "\n",
    "print('random input shape: ', input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = conv_layer(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolution layer를 통해 얻어진 출력 (activation map)으로부터 주요한 정보만을 남기고, 불필요한 정보를 제거하는 레이어 (downsampling 수행)\n",
    "- `pool_size`가 `k` 일 때 `(height, width, channel)`의 shape을 갖는 입력에 대해 `(height/k, width/k, channel)`의 shape을 갖는 출력 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool_layer = tf.keras.layers.MaxPool2D(pool_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Xul6nP7OkdT",
    "outputId": "6dd0c720-f808-4494-f558-d5a3401dcb1a"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "input_height = 28\n",
    "input_width = 28\n",
    "input_channel = 1\n",
    "input = tf.random.normal(shape=[100, 28, 28, 1])\n",
    "\n",
    "print('random input shape: ', input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 9, 9, 1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = maxpool_layer(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uRcQ1FRPWHh"
   },
   "source": [
    "### CNN 모델 정의\n",
    "\n",
    "- Convolution layer와 pooling layer, dense layer를 조합하여 CNN 모델 정의\n",
    "- 정의된 CNN 모델의 **출력 차원은 학습 데이터의 클래스 수**와 일치 해야함\n",
    "    - Fashion MNIST 데이터셋의 경우 총 10개의 클래스 존재\n",
    "\n",
    "**Note**\n",
    "- 마지막에 Dense layer - Softmax layer가 와야함\n",
    "- 이 때 Dense layer 의 출력 차원은 class 개수와 같아야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fx49EOK89wSA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "class SingleLayerCNN(Model):\n",
    "  def __init__(self): # 생성자: 객체가 생성될 때 자동으로 호출되는 메서드 (모델을 구성하는 layer들을 정의)\n",
    "    super(SingleLayerCNN, self).__init__()\n",
    "    self.conv1 = tf.keras.layers.Conv2D(16, 3, activation='relu')\n",
    "    self.maxpool1 = tf.keras.layers.MaxPool2D(2)\n",
    "\n",
    "    self.flatten = tf.keras.layers.Flatten() # 다차원 출력을 1차원 벡터로 변환 (Dense layer에 연결하기 위해 필요한 작업)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(10) # 10개의 클래스에 대한 확률값을 출력하기 위해 10개의 뉴런을 가지는 Dense layer를 정의\n",
    "    self.softmax = tf.keras.layers.Softmax() # 확률값을 계산하기 위해 softmax 함수를 정의    \n",
    "\n",
    "  def call(self, x): # 모델이 호출될 때 자동으로 호출되는 메서드 (모델에 입력이 들어왔을 때의 레이어 연산 순서 정의)\n",
    "    x = self.conv1(x)\n",
    "    x = self.maxpool1(x)\n",
    "    \n",
    "    x = self.flatten(x)\n",
    "    x = self.dense(x)\n",
    "\n",
    "    x = self.softmax(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1\n",
    "\n",
    "- **Goal**: 위의 SingleLayerCNN에 convolution layer와 maxpooling layer를 하나씩 추가해서 TwoLayerCNN 모델을 정의하세요\n",
    "  \n",
    "- **TODO 1**: 아래 `TwoLayerCNN`의 `__init__` 메소드에서 `tf.keras.layers.Conv2D`와 `tf.keras.layers.MaxPool2D`를 사용하여 convolution layer와 maxpooling layer를 추가 선언\n",
    "- **TODO 2**: 아래 `TwoLayerCNN`의 `call` 메소드에서 `self.conv1`과 `self.pool1`을 통과한 출력을 새로 선언한 convolution layer와 maxpooling layer에 순차적으로 입력\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "class TwoLayerCNN(Model):\n",
    "  def __init__(self): # 생성자: 객체가 생성될 때 자동으로 호출되는 메서드 (모델을 구성하는 layer들을 정의)\n",
    "    super(TwoLayerCNN, self).__init__()\n",
    "    self.conv1 = tf.keras.layers.Conv2D(16, 3, activation='relu')\n",
    "    self.maxpool1 = tf.keras.layers.MaxPool2D(2)\n",
    "\n",
    "    # TODO 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    self.flatten = tf.keras.layers.Flatten() # 다차원 출력을 1차원 벡터로 변환 (Dense layer에 연결하기 위해 필요한 작업)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(10) # 10개의 클래스에 대한 확률값을 출력하기 위해 10개의 뉴런을 가지는 Dense layer를 정의\n",
    "    self.softmax = tf.keras.layers.Softmax() # 확률값을 계산하기 위해 softmax 함수를 정의    \n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.maxpool1(x)\n",
    "    \n",
    "    # TODO 2\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    x = self.flatten(x)\n",
    "    x = self.dense(x)\n",
    "\n",
    "    x = self.softmax(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uppD91OTQLRx"
   },
   "source": [
    "# 2-2. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dmMsSg-KUtx"
   },
   "source": [
    "### 모델 인스턴스 생성\n",
    "\n",
    "- 입력 shape을 지정하여 model build 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJg-H3jF_RU6",
    "outputId": "ecddb1ac-a79d-497d-b5d4-01ece5db541a"
   },
   "outputs": [],
   "source": [
    "model = TwoLayerCNN()\n",
    "input_shape = (1,28,28,1)\n",
    "model.build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V11qKR-nP6oU"
   },
   "source": [
    "### 모델 학습을 위한 loss 함수와 optimizer 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tensorflow 에서 지원하는 Loss functions: https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "\n",
    "    - `CategoricalCrossentropy` : label이 onehot encoding (ex. [0, 0, 0, 1]) 형태로 제공되는 경우 사용\n",
    "    - `SparseCategoricalCrossentropy` : label이 integer 형태로 제공되는 경우 사용\n",
    "\n",
    "- Tensorflow 에서 지원하는 Optimizers: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "woySE9WC_mdg"
   },
   "outputs": [],
   "source": [
    "# loss 함수 (분류 모델 학습을 위한 Cross Entropy Loss)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# loss 함수를 minimize 하기 위한 optimizer\n",
    "optimizer = tf.keras.optimizers.Adam() #default arguments: lr: 0.001, beta_1: 0.9, beta_2: 0.999, epsilon: 1e-07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTiY5doSRqKk"
   },
   "source": [
    "### 학습 및 추론 함수 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05lXaQlaRvu-"
   },
   "source": [
    "학습에 필요한 gradient 값을 획득하기 위해서 Tensorflow에서 제공하는 `GradientTape` 객체 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XehfpkBKSgqe"
   },
   "source": [
    "- `GradientTape()` 활용 예시\n",
    "    - $y=x^2$ 함수에 대한 미분을 계산하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JybGHki0ShAX",
    "outputId": "e308539e-94af-48b9-9ea6-6d8db8d27ddc"
   },
   "outputs": [],
   "source": [
    "x = tf.constant(3.0) # x 변수에 상수 값 3.0 할당\n",
    "\n",
    "with tf.GradientTape() as tape: # gradient 계산을 시작하기 위한 with statement\n",
    "  tape.watch(x) # x 변수에 대한 gradient 계산을 위해 x를 watch\n",
    "  y = x * x # y = x^2\n",
    "\n",
    "dy_dx = tape.gradient(y, x) # take the gradient of y with respect to x (dy/dx = 2x)\n",
    "print(f'x={x}\\t', 'dy/dx=2x\\t ', dy_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPMzFZg0S3Kr"
   },
   "source": [
    "- 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "_1KUnOnm-Nuj"
   },
   "outputs": [],
   "source": [
    "def train(model, train_batch_loader, loss_object, optimizer):\n",
    "  for images, labels in train_batch_loader: # train_batch_loader로부터 batch (images, labels)를 가져옴\n",
    "    with tf.GradientTape() as tape: # 그래디언트 계산 시작\n",
    "      outputs = model(images) # batch 단위 이미지를 모델에 입력하여 출력 도출 (Forward)\n",
    "      loss = loss_object(labels, outputs) # 정답 라벨 labels와 모델의 출력 outputs (예측치) 간의 loss 계산\n",
    "    gradients = tape.gradient(loss, model.trainable_variables) # gradient of loss with respect to weight parameters (Back-propagation)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # Adam optimizer를 이용하여 weight parameter 업데이트 \n",
    "\n",
    "\n",
    "# => 전체 학습 데이터셋 (10,000개)에 대해 학습을 수행함 (1 Epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 성능 평가 (test) 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # scikit learn 패키지의 accuracy_score 함수를 이용하여 정확도 계산\n",
    "\n",
    "def test(model, test_batch_loader):\n",
    "    \n",
    "    preds_list = [] # 모델의 예측치를 저장하기 위한 list\n",
    "    labels_list = [] # 정답 라벨을 저장하기 위한 list\n",
    "\n",
    "    for images, labels in test_batch_loader:\n",
    "        outputs = model(images) # batch 단위 이미지를 모델에 입력하여 출력 도출 (Forward)\n",
    "\n",
    "        outputs = outputs.numpy() # 편의를 위해 numpy array로 변환\n",
    "        labels = labels.numpy()\n",
    "\n",
    "        preds = outputs.argmax(axis=1) # 모델의 예측치는 확률값이 가장 큰 클래스 (ex) [0.1, 0.2, 0.7] => 2)로 결정\n",
    "        \n",
    "        preds_list += list(preds) # 예측치를 list에 추가\n",
    "        labels_list += list(labels) # 정답 라벨을 list에 추가\n",
    "\n",
    "    accuracy = accuracy_score(labels_list, preds_list)\n",
    "    return accuracy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2\n",
    "\n",
    "- **Goal**: 위의 학습 함수와 성능평가 함수를 이용하여 모델을 학습하고, 성능을 평가하세요.\n",
    "  \n",
    "- **TODO 1**: `train` 함수를 활용하여 모델을 3 epoch 만큼 학습시키키\n",
    "- **TODO 2**: `test` 함수를 활용하여 학습된 모델 성능을 평가하기\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc91204877c4137c2212b1d61d6534ff6dfb04f40855d2e912a8a7e2bf1bc891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
